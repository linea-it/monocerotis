[{
	"id": 0,
	"speaker": "Alex Szalay",
	"affiliation": "The Institute of Data Intensive Engineering and  Science Johns Hopkins University (IDIES)",
	"title": "The Future of Long Term Data",
	"abstract": "The talk will present a discussion about how science is changing, results in data sets with an ever longer effective lifetime. Many of the current sky-surveys (and other mid-scale projects) generate data sets at a cost of tens to hundreds of millions of dollars, yet there is no coherent strategy to ensure the survival of these data sets.  WE will discuss the different factors related to long term data preservation, the technological changes, and the sociological changes in how data is used, including AI applications.",
	"isOrganizer": false
}, {
	"id": 1,
	"speaker": "Andreas Wicenec",
	"affiliation": "International Centre for Radio Astronomy Research (ICRAR/UWA)",
	"title": "",
	"abstract": "",
	"isOrganizer": true
}, {
	"id": 2,
	"speaker": "Andy Conolly",
	"affiliation": "DIRAC Institute and/e-Science Institute of the University of Washington (DIRAC)",
	"title": "",
	"abstract": "",
	"isOrganizer": false
}, {
	"id": 4,
	"speaker": "Chenzhou Cui",
	"affiliation": "National Astronomical Observatories of China (NAOC)",
	"title": "",
	"abstract": "",
	"isOrganizer": false
}, {
	"id": 5,
	"speaker": "Denny Lee",
	"affiliation": "Databricks",
	"title": "Optimizing LSST Analysis with Apache Spark™",
	"abstract": "With the vast amount of data captured in the night sky, how can we effectively analyze all of this data while also collaborating between different institutions in different geographies, whether on-premises or in the cloud?  It is essential to use a distributed data processing framework designed for collaboration.  Apache Spark™ is the defacto big data standard as it can scale to large datasets across thousands of nodes and cores.  It is a compute engine that works well on-premises and in the cloud.  ",
	"isOrganizer": false
}, {
	"id": 6,
	"speaker": "Dominique Boutigny",
	"affiliation": "French National Institute of Nuclear and Particle Physics (IN2P3/CNRS)",
	"title": "Rubin and DESC computing organization at IN2P3",
	"abstract": "CC-IN2P3 will be in charge of 50% of the Vera C. Rubin Observatory's Data Release Processing and will host a full copy of the data and catalogs. I will describe the computing infrastructure that is being deployed and the organization that we are setting up in France in order to process the Rubin data and to provide the services necessary to access them. I will also explain why it is critical to test and validate the infrastructure and services with real science use cases such as those provided by the Dark Energy Science Collaboration.",
	"isOrganizer": false
}, {
	"id": 7,
	"speaker": "Fabio Hernandez",
	"affiliation": "French National Institute of Nuclear and Particle Physics (IN2P3/CNRS)",
	"title": "",
	"abstract": "",
	"isOrganizer": true
}, {
	"id": 8,
	"speaker": "George Beckett",
	"affiliation": "University of Edinburgh",
	"title": "LSST:UK plans for an Independent Data Access Centre, development roadmap and science ambitions”",
	"abstract": "",
	"isOrganizer": true
}, {
	"id": 9,
	"speaker": "Ian Bird",
	"affiliation": "CNRS-LAPP/ESCAPE",
	"title": "The ESCAPE project - objectives and plans",
	"abstract": "The ESCAPE project brings together 11 ESFRI and other Research Infrastructures in Astronomy, Astro-Particle, Particle and Nuclear Physics fo the first time.  It is one of 5 such thematic science cluster projects that are integrating communities, infrastructure, and research tools as contributions to the European Open Science Cloud (EOSC).  ESCAPE is building a next-generation data management infrastructure (“data-lake”) to provide FAIR data management at exabyte scales, capable of delivering data to distributed high performance analysis and compute facilities.  That is complemented by work on a software infrastructure, enabling the sharing of the research tools and products, an integration of the International Virtual Observatory (IVOA) framework into the proto-EOSC and high level science platforms.  ESCAPE is currently planning two science challenges; one on Dark Matter, and the second on Gravitational Waves and the Extreme Universe, which together will demonstrate the capabilities of open data and cross-domain science.  This talk will give an overview of the ESCAPE work and output, the two science projects, and will look at the prospects for how this all feeds into the first implementation of the EOSC.",
	"isOrganizer": false
}, {
	"id": 18,
	"speaker": "J Ross Thomson",
	"affiliation": "Google LLC",
	"title": "Multi-Cloud and Hybrid Strategies for Scientific Workloads",
	"abstract": "Cloud computing is a fast moving environment offering great flexibility for modern scientific missions to build and optimize applications on Cloud platforms. The velocity of change in cloud computing presents a risk to science missions planning for a decades long project lifetime. In this presentation, we will discuss strategies to minimize risk and increase efficiency in a Multi-Cloud / Hybrid computing environment.",
	"isOrganizer": false
}, {
	"id": 10,
	"speaker": "JJ Kavelaars",
	"affiliation": "Canadian Astronomy Data Center (CADC)",
	"title": "Canadian Astronomy Data Centre (CADC) and the Canadian Advanced Network for Astronomy Research (CANFAR): Building the science portal from inside the data centre.",
	"abstract": "I will describe the evolution of the Canadian Astronomy Data Centre (CADC) from an archive delivering data towards an integrated  science portal development and support group. The CADC is committed to expanding the capacity of the Canadian Advanced Network for Astronomy Research (CANFAR).  I will describe the current state of evolution along this path, the processes we have followed so far, the technologies we are currently developing to enable the archive/portal interaction and our plans for future development.   My goal is to provide examples of the use-case driven evolution of the CADC/CANFAR services and to raise some ",
	"isOrganizer": false
}, {
	"id": 11,
	"speaker": "Jordan Collier",
	"affiliation": "Institute for Data Intensive Astronomy (IDIA)",
	"title": "The MeerKAT toolbelt: a waist of data",
	"abstract": "A number of tools and systems have been developed or adopted to deal with the PB scale of MeerKAT data at the Inter-University Institute for Data Intensive Astronomy (IDIA), Cape Town. I will present a number of these tools and underlying systems, including those for storage, processing, visualisation, and data transfer. I will present a worked example of processing MeerKAT data via the IDIA pipeline, a fully automated end-to-end pipeline that is efficient, flexible, scalable, and user-friendly, and designed to operate across the ilifu cluster using SLURM and MPI. Our unique setup uses an IDIA cloud-based platform running on hardware provided by the ilifu national facility, taking advantage of cluster-level parallelism, resource management and software containers. Altogether this represents a pathfinder science regional data centre, and a good framework for solving many of the broader challenges of the SKA.",
	"isOrganizer": false
}, {
	"id": 12,
	"speaker": "Knut Olsen",
	"affiliation": "NOIRLab",
	"title": "Datasets and Data Services at NOIRLab’s Community Science and Data Center",
	"abstract": "",
	"isOrganizer": false
}, {
	"id": 13,
	"speaker": "Luiz da Costa",
	"affiliation": "Laboratório Interinstitucional de e-Astronomia (LIneA)",
	"title": "",
	"abstract": "",
	"isOrganizer": false,
  "isOwner": true
}, {
	"id": 14,
	"speaker": "Mario Juric",
	"affiliation": "DIRAC Institute/University of Washington (DIRAC)",
	"title": "",
	"abstract": "",
	"isOrganizer": true
}, {
	"id": 15,
	"speaker": "Mark Allen",
	"affiliation": "Centre de Données Astronomiques de Strasbourg (CDS)",
	"title": "CDS services for reference astronomy data - supporting Open Science.",
	"abstract": "The Strasbourg astronomical Data Centre (CDS) provides services for reference data from published journal articles and from large astronomical surveys. The SIMBAD, VizieR, Aladin and the CDS X-Match services are being continuously updated and developed to meet the challenges of the rapidly increasing volumes of data. The services are designed to support Open Science and we will show how this is aimed at facilitating the scientific work of the research community but also the use of research data by educators and planetaria. We highlight the role of IVOA standards for interoperability, and the new approaches made possible by practical tools for manipulating the space- and time-coverage of data sets. We also mention the promising developments for integrating VO compliant services into wider systems such as the European Open Science Cloud.",
	"isOrganizer": false
}, {
	"id": 16,
	"speaker": "Nirav Merchant",
	"affiliation": "CyVerse",
	"title": "Infrastructure as code: Seeing clearly through Cloudy skies",
	"abstract": "",
	"isOrganizer": false
}, {
	"id": 17,
	"speaker": "Richard Dubois",
	"affiliation": "SLAC National Accelerator Laboratory (SLAC)",
	"title": "Rubin US Data Facility",
	"abstract": "Rubin’s 10-year Survey is projected to begin in late 2023: about 20 TB per Chilean night will be delivered to the US Data Facility (US DF). The US DF will perform three major functions: prompt processing to generate transient alerts within 1 minute after exposures were taken; annual reprocessing of all images taken to date; and providing a science platform for analysis to an anticipated 5000-7500 users, dedicating about 10% of the total resource to them. The annual reprocessings will be executed in concert with facilities in France and the UK, and are projected to occupy about 500 PB of nearline storage by year 10.",
	"isOrganizer": false
}, {
	"id": 19,
	"speaker": "Sanjay Padhi",
	"affiliation": "Amazon.com, Inc",
	"title": "",
	"abstract": "",
	"isOrganizer": false
}, {
	"id": 20,
	"speaker": "Simone Campana",
	"affiliation": "Worldwide LHC Computing Grid (WLCG/CERN)",
	"title": "WLCG: a distributed infrastructure for large scale scientific computing",
	"abstract": "The Worldwide LHC Computing Grid collaboration provides the computing infrastructure for the CERN experiments at the Large Hadron Collider. Such an infrastructure is deployed across more than 150 data centres in 42 countries worldwide and provides more than an exabyte of storage and one million CPU cores to the LHC experiments. The CERN LHC program is entering an unprecedented challenging phase, increasing by more than 10 times the computing needs. This contribution will provide an overview of WLCG and present how the infrastructure is evolving in terms of policies and services to face such a challenge, leveraging and adapting to the rapidly changing Information Technology market",
	"isOrganizer": false
}, {
	"id": 21,
	"speaker": "Vandana Desai",
	"affiliation": "IPAC-CALTECH",
	"title": "Enabling next-generation science investigations with the NASA Astrophysics Archives",
	"abstract": "",
	"isOrganizer": false
}, {
	"id": 22,
	"speaker": "Veronique Valette",
	"affiliation": "Centre National d’Études Spatiales (CNES)",
	"title": "CNES computing and data center serving scientific projects: existing and roadmap",
	"abstract": "CNES, French Space Agency is in charge of developing and operating data processing centers for scientific projects,: earth observation, astrophysics, space exploration. The paper will present our existing  data processing center  (HPC, HPSS, Jupyterhub, VRE),  were we want to go in the near future (OpenStack, Datalake, Datalabs) and all the tools that are available for scientists and developers (software factory).  It will also explain how the science projects use this data center now and what are the plans for the future.",
	"isOrganizer": false
}, {
	"id": 23,
	"speaker": "William O’Mullane ",
	"affiliation": "Legacy Survey of Space and Time (LSST)/Vera C. Rubin Observatory",
	"title": "",
	"abstract": "",
	"isOrganizer": true
}]
